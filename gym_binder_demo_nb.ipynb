{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9be983f4",
   "metadata": {},
   "source": [
    "# Gym demo with Binder\n",
    "*From this [post](https://towardsdatascience.com/rendering-openai-gym-envs-on-binder-and-google-colab-536f99391cc7) from David R. Pugh.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af28e037",
   "metadata": {},
   "source": [
    "Starting virtual display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb5fbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvirtualdisplay\n",
    "\n",
    "\n",
    "_display = pyvirtualdisplay.Display(visible=False,  # use False with Xvfb\n",
    "                                    size=(1400, 900))\n",
    "_ = _display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cd7c00",
   "metadata": {},
   "source": [
    "Gym simulation using rgb_array mode with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef5243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "# represent states as arrays and actions as ints\n",
    "State = np.ndarray\n",
    "Action = int\n",
    "\n",
    "# agent is just a function! \n",
    "Agent = typing.Callable[[State], Action]\n",
    "\n",
    "\n",
    "def uniform_random_policy(state: State,\n",
    "                          number_actions: int,\n",
    "                          random_state: np.random.RandomState) -> Action:\n",
    "    \"\"\"Select an action at random from the set of feasible actions.\"\"\"\n",
    "    feasible_actions = np.arange(number_actions)\n",
    "    probs = np.ones(number_actions) / number_actions\n",
    "    action = random_state.choice(feasible_actions, p=probs)\n",
    "    return action\n",
    "\n",
    "\n",
    "def make_random_agent(number_actions: int,\n",
    "                      random_state: np.random.RandomState = None) -> Agent:\n",
    "    \"\"\"Factory for creating an Agent.\"\"\"\n",
    "    _random_state = np.random.RandomState() if random_state is None else random_state\n",
    "    return lambda state: uniform_random_policy(state, number_actions, _random_state)\n",
    "\n",
    "\n",
    "def simulate(agent: Agent, env: gym.Env, ax: plt.Axes) -> None:\n",
    "    state = env.reset()\n",
    "    img = ax.imshow(env.render(mode='rgb_array'))\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent(state)\n",
    "        img.set_data(env.render(mode='rgb_array')) \n",
    "        ax.axis('off')\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        state, reward, done, _ = env.step(action)       \n",
    "    env.close()\n",
    "    \n",
    "# create the Gym environment\n",
    "lunar_lander_v2 = gym.make('LunarLander-v2')\n",
    "_ = lunar_lander_v2.seed(42)\n",
    "\n",
    "# create an agent\n",
    "random_agent = make_random_agent(lunar_lander_v2.action_space.n, random_state=None)\n",
    "\n",
    "# simulate agent interacting with the environment\n",
    "_, ax = plt.subplots(1, 1)\n",
    "simulate(random_agent, lunar_lander_v2, ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
